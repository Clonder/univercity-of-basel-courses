{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adult = pd.read_csv('adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af19429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_over_30_dp(epsilon):\n",
    "    true_answer = len(adult[adult['Age'] > 30])\n",
    "    return laplace_mech(true_answer, 1, epsilon)\n",
    "\n",
    "people_over_30_dp(epsilon = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1b920",
   "metadata": {},
   "source": [
    "In this case, the sensitivity is equal to 1 because adding or removing a single person from the dataset can change the count of people over 30 by at most 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_crosstab_education_sex(epsilon):\n",
    "    ct  = pd.crosstab(adult['Education'], adult['Sex'])\n",
    "    sensitivity = 1\n",
    "    noisy_ct = ct.applymap(lambda x: laplace_mech(x, sensitivity, epsilon))\n",
    "\n",
    "    return noisy_ct\n",
    "\n",
    "dp_crosstab_education_sex(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f5fc7",
   "metadata": {},
   "source": [
    "For a histogram with any number of dimensions (here 2), parallel composition holds because adding or removing an individual in the data changes exactly one count in the histogram. \n",
    "\n",
    "In terms of privacy cost, the number of columns doesn't matter because the sensitivity remains the same regardless of the number of dimensions. Each change in the dataset affects only one count in the histogram.\n",
    "\n",
    "However, accuracy is crucial. The more columns you group by, the smaller the count will be in each resulting cell of the histogram. While the noise level remains constant, the signal-to-noise ratio decreases as the counts become smaller, potentially affecting the accuracy of the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7842d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madult\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarital Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      3\u001b[0m options \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNever-married\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarried-civ-spouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDivorced\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarried-spouse-absent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeparated\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarried-AF-spouse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWidowed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(option):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult' is not defined"
     ]
    }
   ],
   "source": [
    "adult['Marital Status'].value_counts()\n",
    "\n",
    "options = ['Never-married', 'Married-civ-spouse', 'Divorced',\n",
    "           'Married-spouse-absent', 'Separated', 'Married-AF-spouse',\n",
    "           'Widowed']\n",
    "\n",
    "\n",
    "def score(option):\n",
    "    count = len(adult[adult['Marital Status'] == option])\n",
    "    return count\n",
    "\n",
    "score('Never-married')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87d655-1e0b-4474-92a2-7798eed3e572",
   "metadata": {},
   "source": [
    "Sensitivity is 1, using a counting query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7925b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_marital_status(R, score, sensitivity, epsilon):\n",
    "    #  Calculate scores for each option\n",
    "    scores = [score(r) for r in R]\n",
    "\n",
    "    # Add Laplace noise to each score\n",
    "    noisy_scores = [laplace_mech(s, sensitivity, epsilon) for s in scores]\n",
    "\n",
    "    # Select the option with the highest noisy score\n",
    "    max_idx = np.argmax(noisy_scores)\n",
    "    selected_option = R[max_idx]\n",
    "\n",
    "    return selected_option\n",
    "    \n",
    "most_common_marital_status(options, score, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeddd67",
   "metadata": {},
   "source": [
    "- When considering 7 options for R, the Laplace mechanism is employed 7 times, with a sensitivity of 1 for the scoring function. According to sequential composition, the cumulative privacy cost becomes 7 times the epsilon value. Through post-processing, the ultimate privacy cost remains at 7 times epsilon. Since reporting the noisy maximum is akin to using the exponential mechanism, the final deduction is that the total privacy cost is reduced to just epsilon. Answer: epsilon, so here 1.\n",
    "- Moreover the algorithm defined above satisfies e-differential privacyt, regardless of set size.  because it releases only the identity of the element with the largest noisy count. The proof can be found in Dwork and Roth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_sum_capgain(epsilon):        \n",
    "    upper_bound = adult['Capital Gain'].max() # The upper bound of our data\n",
    "    clipped_sum = adult['Capital Gain'].clip(lower = 0, upper = upper_bound).sum()\n",
    "    noisy_sum = laplace_mech(clipped_sum, upper_bound + 1, epsilon)\n",
    "    \n",
    "    return noisy_sum\n",
    "\n",
    "dp_sum_capgain(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd333e0e-273d-42a4-840b-4b748d1903d2",
   "metadata": {},
   "source": [
    "- The clipping parameter I chose for the dp_sum_capital function was the max value for the dataset, 99,999. I chose this value because there is no person exhibting more than a value of 99,999 for the capital gain column and thus it is safe to assume 100% of the database is included within the clipping.\n",
    "  \n",
    "- The sensitivity of the query used to compute dp_sum_capital is 100,000. This is because a summation query is unbounded in nature, meaning if a new row were added to the dataset the summation query would then be offset by the amount of the added row. But since our data ranges from 0 to 99,999 it is safe to safe that 100,00 will account for any value in our query that should be added into our dataset, so we can assume a sensitivity of the difference of the lower and upper bounds (with a little padding).\n",
    "\n",
    "- My definition of dp_sum_capital has a total privacy cost of epsilon. This is because we are only creating one noisy sum here, so the amount of privacy we are using is exactly what is passed in as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51854bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_cdf():\n",
    "    a = adult['Age']\n",
    "    return [len(a[a < i]) for i in range(100)]\n",
    "\n",
    "plt.plot(age_cdf());\n",
    "print('Length of CDF vector:', len(age_cdf()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3572f",
   "metadata": {},
   "source": [
    "- The sensitivity of each individual count (element-wise sensitivity) in the vector is 1, as adding or removing a single individual can change the count by at most 1.\n",
    "\n",
    "- The squared sensitivity of each individual count is 1 * 1 = 1.\n",
    "\n",
    "- Since there are 100 counts in the vector, the L2 global sensitivity is the square root of the sum of the squares of the element-wise sensitivities, which is 100.\n",
    "\n",
    "- The L1 sensitivity is the sum of the individual sensitivities, i.e., 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc1210-888a-4676-bb84-48d728d00e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mech_RDP(val, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return val + np.random.normal(loc=0, scale=sigma)\n",
    "\n",
    "def gaussian_mech_RDP_vec(vec, sens, alpha, epsilon):\n",
    "    return [gaussian_mech_RDP(x, sens, alpha, epsilon) for x in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cdf(df, epsilon=1.0):\n",
    "    true_cdf_vals = age_cdf()\n",
    "    \n",
    "    alpha = 5\n",
    "    epsilon_bar = 0.001\n",
    "    \n",
    "    L2_sens = np.sqrt(len(df))\n",
    "    \n",
    "    noisy_cdf = gaussian_mech_RDP_vec(true_cdf_vals, L2_sens, alpha, epsilon)\n",
    "    \n",
    "    return noisy_cdf\n",
    "\n",
    "# Calculate CDF with differential privacy\n",
    "cdf_vals = calculate_cdf(adult)\n",
    "# Plot CDF\n",
    "plt.plot(cdf_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2a84a",
   "metadata": {},
   "source": [
    "\n",
    "- What is the *total privacy cost* in RDP of your solution above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c463b0f",
   "metadata": {},
   "source": [
    "Utilize the L2 sensitivity to calculate the cumulative distribution function (CDF) vector. Each query within this vector is a counting query with a sensitivity of 1. Consequently, the overall L2 sensitivity amounts to the square root of len(data). Apply the Gaussian mechanism once, incurring a total privacy cost of (alpha, epsilon)-RDP, so alpha = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5aaee",
   "metadata": {},
   "source": [
    "- What is the *total privacy cost* in $(\\epsilon, \\delta)$-differential privacy of your solution above, for $\\delta = 10^{-5}$? Implement the function `convert_RDP_ED` to convert the RDP parameters to $(\\epsilon, \\delta)$-DP parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_RDP_ED(alpha, epsilon_bar, delta):\n",
    "    epsilon = epsilon_bar + (np.log(1/delta) / (alpha -1))\n",
    "    return epsilon\n",
    "\n",
    "convert_RDP_ED(5, .0001, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7a426-53d5-4feb-ac2c-fbd80e47c94b",
   "metadata": {},
   "source": [
    "The total privacy cost is (2.878, 1e-5)-differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094749fc-0a59-465f-9bc9-88ba9ab4adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a single occupation from the adult dataset, and return a single response\n",
    "def encode_response_sales(response, alpha):\n",
    "    if random.random() < (1/2 + alpha):\n",
    "        if response == 'Sales':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if response == 'Sales':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "def decode_responses_sales(responses, alpha):\n",
    "    return sum([((y - 1/2 + alpha) / 2 * alpha) for y in responses])\n",
    "\n",
    "alpha = 0.05\n",
    "responses = [encode_response_sales(r, alpha) for r in adult['Occupation']]\n",
    "decode_responses_sales(responses, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745e20b-b1c7-43b2-b208-44943b94fe42",
   "metadata": {},
   "source": [
    "#### Version from the [book](https://programming-dp.com/ch13.html), mechanism by Dwork and Roth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbaceaa-34ec-46f3-8fea-d71da5b8793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rand_resp_yes_no(true_response):\n",
    "    if random.random() < (1/2 + alpha):\n",
    "        return true_response\n",
    "    else:\n",
    "        if random.random() < (1/2 + alpha):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f859f8-9c93-4ae2-9475-4e96de5e91d6",
   "metadata": {},
   "source": [
    "- With probability 1/2 - alpha each respondant responds randomly and with probability 1/2 + 0.05, each random response is a \"yes\", so the probability that a respondant responds “yes” by random cis (1/2 - 0.05) * (1/2 + 0.05) = 0.2475.\n",
    "- The other factor we need to consider is that half of the respondants answer randomly, but some of the random respondants might actually be salespeople. But, since we split the respondants into “truth” and “random” groups randomly, we can hope that there are roughly the same number of salespeople in both groups. Since alpha is quite small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba9e39-4b0b-49c9-8332-87d780a87821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rand_resp_yes_no(responses):\n",
    "    # Decode the results of randomized responses\n",
    "    all_yes = np.sum(responses)\n",
    "    \n",
    "    # Subtract the number of fake yesses\n",
    "    fake_yes = (0.2475)*len(responses)\n",
    "    true_yes = all_yes - fake_yes\n",
    "    \n",
    "    # Multiply by 2\n",
    "    return 2*true_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f8707-1668-49ad-af23-6df163345529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a single occupation from the adult dataset, and return a single response\n",
    "def encode_response_sales(response):\n",
    "    randomized_response = encode_rand_resp_yes_no(response == 'Sales')\n",
    "    return randomized_response\n",
    "    \n",
    "def decode_responses_sales(responses):\n",
    "    approximate_yesses = decode_rand_resp_yes_no(responses)\n",
    "    return approximate_yesses\n",
    "\n",
    "responses = [encode_response_sales(r) for r in adult['Occupation']]\n",
    "decode_responses_sales(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef7200-4a75-451f-8806-190207595e46",
   "metadata": {},
   "source": [
    "Better answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How accurate is the answer above?\n",
    "true_sales = np.sum(adult['Occupation'] == 'Sales')\n",
    "print('True number of salespeople:', true_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2350c4-d33e-444b-8783-83b308e36f3f",
   "metadata": {},
   "source": [
    "We have that $$\\epsilon = \\ln (\\frac{\\alpha+1}{\\alpha-1}) = 0.1$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
